# Configuration for Transformer Model (DistilBERT)

# Model settings
model:
  name: "distilbert-base-uncased"
  num_labels: null  # Will be set automatically based on dataset
  max_seq_length: 32  # SUPER REDUCED for ultra-fast testing

# Training hyperparameters
training:
  train_batch_size: 64  # MAXIMIZED for fastest training
  eval_batch_size: 128  # MAXIMIZED for fastest evaluation
  learning_rate: 5.0e-5  # Higher for faster convergence
  num_train_epochs: 1   # MINIMAL - just 1 epoch
  weight_decay: 0.01
  warmup_ratio: 0.0     # NO WARMUP for fastest start
  gradient_accumulation_steps: 1
  max_grad_norm: 1.0
  
  # Optimization
  fp16: false  # Set to true if GPU supports mixed precision
  fp16_opt_level: "O1"
  
  # Early stopping
  early_stopping:
    enabled: false  # DISABLED for quick testing
    patience: 3
    metric: "eval_f1_macro"  # Metric to monitor
    mode: "max"  # "max" for metrics to maximize, "min" for loss
  
  # Learning rate scheduler
  lr_scheduler:
    type: "constant"  # NO SCHEDULING for speed
  
  # Logging
  logging_steps: 10      # Very frequent updates
  eval_steps: 500        # EVAL ONLY ONCE at end
  save_steps: 500        # SAVE ONLY ONCE at end
  save_total_limit: 1    # Only 1 checkpoint

# Data paths
data:
  train_path: "data/processed/train.csv"
  val_path: "data/processed/val.csv"
  test_path: "data/processed/test.csv"

# Model save paths
model_save_dir: "models/transformer/distilbert"

# Reproducibility
seed: 42

# Evaluation settings
evaluation:
  metrics:
    - "accuracy"
    - "f1_macro"
    - "f1_weighted"
    - "precision_macro"
    - "recall_macro"
  save_confusion_matrix: true
  save_classification_report: true
  compute_roc_auc: true  # For binary classification or OvR

# Device settings
device: "cuda"  # Options: "cuda", "cpu", "mps" (for Mac M1/M2)
