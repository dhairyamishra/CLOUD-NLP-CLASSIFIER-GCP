# üöÄ Streamlit UI - Quick Reference Card

## üìã Documents Created

1. **`STREAMLIT_UI_TASK_LIST.md`** - Comprehensive task breakdown (10 phases, 100+ tasks)
2. **`STREAMLIT_UI_OVERVIEW.md`** - Visual overview and architecture
3. **`STREAMLIT_UI_QUICK_REF.md`** - This quick reference (you are here)

---

## üéØ What We're Building

**A minimal Streamlit web UI with:**
- üéõÔ∏è **Sidebar**: Model selection (3 models: LogReg, SVM, DistilBERT)
- üí¨ **Chat Interface**: Text input + conversation history
- üìä **Results Display**: Sentiment analysis with confidence scores
- ‚ö° **Real-time Inference**: < 2 seconds per prediction

---

## üìÅ Files to Create

### Core Files (Required)
```
src/ui/
‚îú‚îÄ‚îÄ streamlit_app.py              # Main app (150-200 lines)
‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îú‚îÄ‚îÄ sidebar.py                # Model selection (80-100 lines)
‚îÇ   ‚îú‚îÄ‚îÄ chat_interface.py         # Chat UI (100-120 lines)
‚îÇ   ‚îî‚îÄ‚îÄ results_display.py        # Results formatting (60-80 lines)
‚îî‚îÄ‚îÄ utils/
    ‚îú‚îÄ‚îÄ model_manager.py          # Model loading (120-150 lines)
    ‚îú‚îÄ‚îÄ inference_handler.py      # Predictions (100-120 lines)
    ‚îî‚îÄ‚îÄ helpers.py                # Utilities (50-80 lines)

.streamlit/
‚îî‚îÄ‚îÄ config.toml                   # Theme config (20-30 lines)

scripts/
‚îú‚îÄ‚îÄ run_streamlit_local.sh        # Linux/Mac (10 lines)
‚îú‚îÄ‚îÄ run_streamlit_local.ps1       # Windows (10 lines)
‚îî‚îÄ‚îÄ run_streamlit.py              # Cross-platform (15 lines)
```

**Total Code**: ~900-1200 lines across 10 files

---

## ‚ö° Quick Start (After Implementation)

### Install
```bash
pip install streamlit>=1.28.0
```

### Run
```bash
# Windows
.\scripts\run_streamlit_local.ps1

# Linux/Mac
bash scripts/run_streamlit_local.sh

# Direct
streamlit run src/ui/streamlit_app.py
```

### Access
```
http://localhost:8501
```

---

## üèóÔ∏è Implementation Order

### Phase 1: Setup (30 min)
```bash
# 1. Update requirements.txt
echo "streamlit>=1.28.0" >> requirements.txt

# 2. Create directories
mkdir -p src/ui/components src/ui/utils .streamlit

# 3. Create __init__.py files
touch src/ui/__init__.py
touch src/ui/components/__init__.py
touch src/ui/utils/__init__.py
```

### Phase 2: Model Loading (1-2 hours)
- Create `model_manager.py` - Load all 3 models
- Create `inference_handler.py` - Handle predictions
- Implement caching with `@st.cache_resource`

### Phase 3: UI Components (2-3 hours)
- Create `sidebar.py` - Model selection dropdown
- Create `chat_interface.py` - Text input + history
- Create `results_display.py` - Format results

### Phase 4: Main App (1-2 hours)
- Create `streamlit_app.py` - Wire everything together
- Implement session state management
- Handle user interactions

### Phase 5: Testing (1 hour)
- Test all 3 models
- Test edge cases
- Manual UI testing

### Phase 6: Documentation (1 hour)
- Create user guide
- Update README
- Add screenshots

---

## üé® Key Code Snippets

### Model Loading (model_manager.py)
```python
import streamlit as st
import joblib
from transformers import AutoModelForSequenceClassification, AutoTokenizer

@st.cache_resource
def load_models():
    """Load all models and cache them"""
    models = {}
    
    # Baseline models
    models['logreg'] = joblib.load('models/baselines/logistic_regression_tfidf.joblib')
    models['svm'] = joblib.load('models/baselines/linear_svm_tfidf.joblib')
    
    # Transformer
    models['distilbert'] = {
        'model': AutoModelForSequenceClassification.from_pretrained('models/transformer/distilbert/'),
        'tokenizer': AutoTokenizer.from_pretrained('models/transformer/distilbert/')
    }
    
    return models
```

### Sidebar (sidebar.py)
```python
def render_sidebar(models):
    """Render model selection sidebar"""
    st.sidebar.title("ü§ñ Cloud NLP Classifier")
    
    # Model selection
    model_options = {
        'Logistic Regression (Baseline)': 'logreg',
        'Linear SVM (Baseline)': 'svm',
        'DistilBERT (Transformer)': 'distilbert'
    }
    
    selected = st.sidebar.selectbox(
        "Select Model:",
        options=list(model_options.keys())
    )
    
    return model_options[selected]
```

### Chat Interface (chat_interface.py)
```python
def render_chat_interface():
    """Render chat input and history"""
    # Display chat history
    for msg in st.session_state.chat_history:
        if msg['role'] == 'user':
            st.chat_message("user").write(msg['content'])
        else:
            st.chat_message("assistant").write(msg['content'])
    
    # Input area
    user_input = st.chat_input("Enter text to analyze...")
    
    return user_input
```

### Main App (streamlit_app.py)
```python
import streamlit as st
from components.sidebar import render_sidebar
from components.chat_interface import render_chat_interface
from utils.model_manager import load_models
from utils.inference_handler import predict

# Page config
st.set_page_config(
    page_title="Cloud NLP Classifier",
    page_icon="ü§ñ",
    layout="wide"
)

# Initialize session state
if 'chat_history' not in st.session_state:
    st.session_state.chat_history = []

# Load models
models = load_models()

# Render UI
selected_model = render_sidebar(models)
user_input = render_chat_interface()

# Handle input
if user_input:
    # Add user message
    st.session_state.chat_history.append({
        'role': 'user',
        'content': user_input
    })
    
    # Get prediction
    result = predict(user_input, selected_model, models)
    
    # Add bot response
    st.session_state.chat_history.append({
        'role': 'assistant',
        'content': result
    })
    
    st.rerun()
```

---

## üìä Estimated Time

| Phase | Core Features | With Optional |
|-------|--------------|---------------|
| **Setup** | 30 min | 30 min |
| **Model Loading** | 1-2 hours | 1-2 hours |
| **UI Components** | 2-3 hours | 3-4 hours |
| **Main App** | 1-2 hours | 2-3 hours |
| **Testing** | 1 hour | 1-2 hours |
| **Documentation** | 1 hour | 2 hours |
| **Scripts** | 30 min | 1 hour |
| **TOTAL** | **6-10 hours** | **12-20 hours** |

---

## ‚úÖ Checklist

### Before Starting
- [ ] All 3 models are trained and saved
- [ ] FastAPI server works (for reference)
- [ ] Python environment is set up
- [ ] Review task list and approve scope

### Core Implementation
- [ ] Phase 1: Setup (dependencies, structure)
- [ ] Phase 2: Model loading (ModelManager)
- [ ] Phase 3: UI components (sidebar, chat, results)
- [ ] Phase 4: Main app (wire everything)
- [ ] Phase 5: Testing (all models work)
- [ ] Phase 6: Documentation (guides)
- [ ] Phase 7: Scripts (run commands)

### Optional Enhancements
- [ ] Analytics dashboard
- [ ] Batch processing
- [ ] Model comparison
- [ ] Export functionality
- [ ] Docker integration
- [ ] Cloud deployment

---

## üéØ Success Criteria

- ‚úÖ UI loads in < 5 seconds
- ‚úÖ All 3 models work correctly
- ‚úÖ Inference < 2 seconds per request
- ‚úÖ Chat history displays properly
- ‚úÖ Results are accurate and well-formatted
- ‚úÖ No crashes during normal use
- ‚úÖ Intuitive and easy to use

---

## üö® Common Issues & Solutions

### Issue: Models not loading
**Solution**: Check file paths, ensure models are trained

### Issue: Slow inference
**Solution**: Use GPU, reduce max_seq_length, or use baseline models

### Issue: Memory errors
**Solution**: Load only one model at a time, or use smaller batch size

### Issue: UI not updating
**Solution**: Use `st.rerun()` after state changes

### Issue: Streamlit Cloud deployment fails
**Solution**: Reduce memory usage, deploy only transformer model

---

## üìö Resources

### Documentation
- **Streamlit Docs**: https://docs.streamlit.io/
- **Streamlit API Reference**: https://docs.streamlit.io/library/api-reference
- **Streamlit Cheat Sheet**: https://docs.streamlit.io/library/cheatsheet

### Examples
- **Streamlit Gallery**: https://streamlit.io/gallery
- **Chat Apps**: https://docs.streamlit.io/knowledge-base/tutorials/build-conversational-apps

### Deployment
- **Streamlit Cloud**: https://streamlit.io/cloud (Free tier available)
- **Docker**: Use existing Dockerfile as reference
- **GCP Cloud Run**: Similar to FastAPI deployment

---

## üé® UI Preview (Mockup)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ ü§ñ Cloud NLP Classifier                                          ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ             ‚îÇ  üí¨ Sentiment Analysis Chat                        ‚îÇ
‚îÇ Select      ‚îÇ                                                     ‚îÇ
‚îÇ Model:      ‚îÇ  You: "I love this product!"                       ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îÇ
‚îÇ ‚îÇDistilBERT‚îÇ‚îÇ  ‚îÇ ü§ñ Bot: ‚úÖ Non-Hate Speech                    ‚îÇ‚îÇ
‚îÇ ‚îÇ    ‚ñº    ‚îÇ‚îÇ  ‚îÇ Confidence: 98.5% | ‚è±Ô∏è 45ms                   ‚îÇ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ  ‚îÇ ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà Non-Hate: 98.5%          ‚îÇ‚îÇ
‚îÇ             ‚îÇ  ‚îÇ ‚ñà‚ñà Hate: 1.5%                                 ‚îÇ‚îÇ
‚îÇ üìä Model    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ
‚îÇ Info:       ‚îÇ                                                     ‚îÇ
‚îÇ ‚Ä¢ Accuracy: ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îÇ
‚îÇ   92.5%     ‚îÇ  ‚îÇ üí≠ Enter your text here...                    ‚îÇ‚îÇ
‚îÇ ‚Ä¢ F1: 0.91  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ
‚îÇ ‚Ä¢ Speed:    ‚îÇ                                          [Submit] üöÄ‚îÇ
‚îÇ   ~50ms     ‚îÇ                                                     ‚îÇ
‚îÇ             ‚îÇ                                                     ‚îÇ
‚îÇ [Clear      ‚îÇ                                                     ‚îÇ
‚îÇ  History]   ‚îÇ                                                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üìû Next Steps

1. **Review** the detailed task list: `docs/STREAMLIT_UI_TASK_LIST.md`
2. **Check** the visual overview: `docs/STREAMLIT_UI_OVERVIEW.md`
3. **Approve** the scope and features
4. **Start** with Phase 1 (Setup)
5. **Iterate** through phases 2-7
6. **Test** and polish
7. **Deploy** and document

---

**Ready to start?** Let me know and we'll begin with Phase 1! üöÄ

---

**Document Version**: 1.0  
**Created**: 2025-12-09  
**Status**: Ready for Review ‚úÖ
